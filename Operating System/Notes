What happens when we press the Power Button( in Linux)?
1. BIOS( Basic Input / Output System ) -> Also called POST( Power on Self Test). Initializes the screen and keyboard and tests the main memory
2. Master Boot Record( MBR ) and Boot Loader -> Searches for GRUB in the bootable partition and loads into RAM
3. Boot Loader( Eg: GRUB) : Loads Kernel and RAM based filesystem( initramfs)
4. Kernel : Initializes and configures the computer's memory and configures all the hardware attached to the system.
5. initramfs : Mounts file system and device drivers
6. /sbin/init : Starts other processes to get the system running.
7. Command shell using getty
8. X windows system

Process Management
--------------------
Process : Program in execution. Eg: command shell, web browser etc
Contains the following section:
Heap: Dynamic allocation
Stack : Temporary data
Data section : Global data
Text section : Program counter

Parts of Program Control Bloc( PCB) - Each process has its own PCB
1. Process Id
2. Process state
3. CPU registers : Must be restored
4. Accounts information
5. I/O status information
6. CPU Scheduling

Context switching : Can either be thread switch or process switch. Happens when
- A high priority process comes to the ready state
- Interrupt occurs
- User and kernel mode switch( Not necessarily)
- Preemptive CPU scheduling is used.

Processes can either be CPU bound or I/O bound.
The time taken to switch between the user and kernel mode is lesser than the time taken to switch from one process to another as the
latter involves mode switch.
fork() system call returns 0  in child process and process id of child process in parent processs.
A process with n fork() system calls generates 2n â€“ 1 child processes.
 
Processes vs Threads
---------------------
Threads share same address space but have different stack. Otherwise it wouldn't be possible to run different code on each of them.
A thread shares with other threads of the same process the code section, the data section, files and signals.
If we want to switch between two threads in Java, we can use sleep method.

class ClassB extends Thread{
	public void run() {
		for (int i = 0; i < 5 ; i++) {
			try {
				Thread.sleep(1000);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
			System.out.println("This is A and B");
		}
	}	
}
 
class ClassA extends Thread {
	public void run(){
			for (int i = 0; i < 5 ; i++) {
				try {
					Thread.sleep(1000);
				} catch (InterruptedException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
				System.out.println("This is A or B");
			}		
	}
}

public class HelloWorld{
public static void main(String[] args) {
		ClassA obj1 = new ClassA();
		ClassB obj2 = new ClassB();
		obj1.start();		
		obj2.start();
	}
}
Above program outputs: 
This is A and B
This is A or B
This is A and B
This is A or B
This is A and B
This is A or B
This is A and B
This is A or B
This is A and B
This is A or B

Throughput: Number of processes that complete their execution per unit time.

Why do we need scheduling?
- Maximum CPU utilization
- Fair allocation of CPU
- Maximum throughput, minimum turnaround time, minimum waiting time and minimum response time

Different scheduling algorithms
---------------------------------
1. FCFS : First come first served . Non preemptive
2. SJF : Shortest Job first. Can cause starvation if short processes keep coming. Minimum average waiting time. Non preemptive
3. SRTF : Shorted remaining time first. Can cause starvation is short processes keep coming. 
4. Priority based scheduling( Non preemptive)
5. Highest Response Ration first : Avoid starvation. 
6. Multilevel Queue scheduling : Different queues( low priority and high priority). Serve high priority first.
7. Multilevel Feedback queue scheduling : If process uses too much CPU time, moved to lower priority queue.
8. Round Robin : Preemptive
Preemptive schueduling can cause starvation. Round robin is better than FCFS in response time.
If the time quatum is very large, Round Robin is equivalent to FCFS.

Convoy effect: Convoy effect is a phenomenon due to FCFS algorithm in which the whole OS slows down due to few slow processes. Leads to
wastage of CPU time and other devices.

Burst time : Amount of time process spends in CPU
Turn around time : Completion Time - Arrival time
Waiting time : Turn around Time - Burst time

3 types of schedulers:
-----------------------
1. Long Term or Job scheduler : Brings a new process to the ready state. Controls degree of multi programming i.e number of process
present in the ready state at any point of time.
2. Short term or CPU scheduler : Selects process but doesn't load from Ready -> Running. Dispatcher loads.
Dispatcher duties : Context switching, Switching to user mode and jumping to proper location in newly loaded program.
3. Medium Term scheduler : Responsible for suspending and resuming the process

Process Synchronization
------------------------
Process synchronization problem arises in case of cooperative processes.
Critical section: A code segment that can be accessed by only one process at a time.
A solution for the critical section problem must satisfy the following three conditions:
1. Mutual Exclusion: If a process Pi is executing in its critical section, then no other process is allowed to enter into the critical section.
2. Progress: If no process is executing in the critical section, then the decision of a process to enter a critical section cannot be made by any other process that is executing in its remainder section. The selection of the process cannot be postponed indefinitely.
3. Bounded Waiting: There exists a bound on the number of times other processes can enter into the critical section after a process has made request to access the critical section and before the requested is granted.

Peterson's solution is a solution for Critical section problem.
flag[0] = true; // I want to enter the CS
P0_gate: turn = 1; // Let another enter 
         while (flag[1] == true && turn == 1)
         {
             // busy wait
         }
         // critical section
         ...
         // end of critical section
         flag[0] = false;

Problem with Peterson's solution:
1. Involves busy waiting
2. Limited to 2 processes.

Solution of busy waiting? Yield
The java.lang.Thread.yield() method causes the currently executing thread object to temporarily pause and allow other threads to execute.
yield(), there's still no guarantee that the same thread won't be selected for execution again, given a pool of equal priority threads.

Monitor: One way to achieve synchronization. Has wait() and notify() method.

TestAndSet : Hardware solution to the synchronized problem. We have a shared lock variable which can take 2 values : either 0 or 1.
Takes lock and executes CS or waits for the lock to be free, takes it and does CS work.
Mutual exclusion and Progress are preserved but Bounded wait is not preserved.

Semaphores : Signalling mechanism vs Mutex : Locking mechanism
Semaphores : Counting or Binary( 0 or 1)
Semaphores: Used to control the number of shared access to a resource. 
Mutex can only  be released by the thread that acquired it while you can signal semaphore from another thread or process.
Ownership is not generally there with semaphore.
Eg: 4KB buffer memory  can be divided into 4 1KB memory each and producer consumer can work on different buffers at the same time.

Note that there can be recursive mutex( can be locked several times). Needs to be unlocked same number of times else deadlock.

Spinlock :  A spinlock is a lock which causes a thread trying to acquire it to simply wait in a loop ("spin") while repeatedly checking if the 
lock is available. Since the thread remains active but is not performing a useful task, the use of such a lock is a kind of busy waiting.
Useful for short locks and not longer ones. Often used in kernel.

A semaphore is a very relaxed type of lockable object. A given semaphore has a predefined maximum count, and a current count. 
You take ownership of a semaphore with a wait operation, also referred to as decrementing the semaphore, or even just abstractly 
called P. You release ownership with a signal operation, also referred to as incrementing the semaphore, a post operation, or
abstractly called V. The single-letter operation names are from Dijkstra's original paper on semaphores.
Every time you wait on a semaphore, you decrease the current count. If the count was greater than zero then the decrement just 
happens, and the wait call returns. If the count was already zero then it cannot be decremented, so the wait call will block 
until another thread increases the count by signalling the semaphore.
Every time you signal a semaphore, you increase the current count. If the count was zero before you called signal, and there 
was a thread blocked in wait then that thread will be woken. If multiple threads were waiting, only one will be woken. 
If the count was already at its maximum value then the signal is typically ignored, although some semaphores may report an error.

Whereas mutex ownership is tied very tightly to a thread, and only the thread that acquired the lock on a mutex can release it, 
semaphore ownership is far more relaxed and ephemeral. Any thread can signal a semaphore, at any time, whether or not that thread
has previously waited for the semaphore.

An analogy
A semaphore is like a public lending library with no late fees. They might have 5 copies of C++ Concurrency in Action available to 
borrow. The first five people that come to the library looking for a copy will get one, but the sixth person will either have to wait,
or go away and come back later.
The library doesn't care who returns the books, since there are no late fees, but when they do get a copy returned, 
then it will be given to one of the people waiting for it. If no-one is waiting, the book will go on the shelf until someone 
does want a copy.

Reader Writer Problem
----------------------
Some threads may read and some may write, with the constraint that no process may access the shared resource for either reading or writing 
while another process is in the act of writing to it. (In particular, it is allowed for two or more readers to access the share at the same time.) 
A readers-writer lock is a data structure that solves one or more of the readers-writers problems.

Banker's algorithm
--------------------
A deadlock avoidance algorithm. We are given an Allocation and max matrix. Now we need to compute need matrix and find safety sequence:
Need = Max - Allocation
New Avaialable at every state = Available + Allocation if the need is less than available.

Priority Inversion vs Priority Inheritance
-------------------------------------------
Priority inversion is the problem and priority inheritance is the solution.
If there are 3 processes and common code for High and low priority process and separate code for medium priority process, then due to
the interruption of low priority thread by medium priority thread,the medium priority thread starts running.
Due to this, it delays both low and high. High is of higher priority than the medium and does not share code with it but it is forced
to wait for medium. This is called priority inversion.
Solution : Low can inherit the priority of High while executing in CS. Low goes back to the old priority when low comes out of critical section.

Deadlock
----------
1. Mutual exclusion : One or more than one resource are non-sharable (Only one process can use at a time)
2. Hold and wait : A process is holding at least one resource and waiting for resources.
3. No preemption : A resource cannot be taken from a process unless the process releases the resource.
4. Circular wait : A set of processes are waiting for each other in circular form.

Interprocess communication can happen in 2 ways:
1. Message passing : Establish a link. Send and receive
2. Shared memory : Eg: Producer consumer problem

Paging and Segmentation : 
----------------------------
Page : Logical unit
Frame : Physical unit
Need to map logical unit to physical unit. Done by MMU through page table.
